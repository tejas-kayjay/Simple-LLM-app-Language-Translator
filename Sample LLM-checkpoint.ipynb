{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "214d61fb",
   "metadata": {},
   "source": [
    "## What is Langchain?\n",
    "\n",
    "LangChain is an open-source framework that helps developers build applications that use large language models (LLMs). LLMs are AI models that can answer questions or create images based on text.\n",
    "\n",
    "\n",
    "## What is Langsmith?\n",
    "\n",
    "LangSmith is an all-in-one developer platform for every step of the LLM-powered application lifecycle, whether you're building with LangChain or not. Debug, collaborate, test, and monitor your LLM applications.\n",
    "\n",
    "LangChain is a framework for building applications using large language models (LLMs), while LangSmith is a tool for debugging and monitoring those applications. Both tools are used in the development of AI and NLP applications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8b8abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "284cfa06",
   "metadata": {},
   "source": [
    "# ----Build a simple LLM application with chat models and prompt templates----\n",
    "\n",
    "- Reference- https://python.langchain.com/docs/tutorials/llm_chain/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9d7e08",
   "metadata": {},
   "source": [
    "In this quickstart we'll show you how to build a simple LLM application with LangChain. This application will translate text from English into another language. This is a relatively simple LLM application - it's just a single LLM call plus some prompting. Still, this is a great way to get started with LangChain - a lot of features can be built with just some prompting and an LLM call!\n",
    "\n",
    "After reading this tutorial, you'll have a high level overview of:\n",
    "\n",
    "- Using language models\n",
    "\n",
    "- Using prompt templates\n",
    "\n",
    "- Debugging and tracing your application using LangSmith\n",
    "\n",
    "Let's dive in!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e29745fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in e:\\anaconda\\lib\\site-packages (0.3.19)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in e:\\anaconda\\lib\\site-packages (from langchain) (3.11.12)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in e:\\anaconda\\lib\\site-packages (from langchain) (2.10.6)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in e:\\anaconda\\lib\\site-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in e:\\anaconda\\lib\\site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in e:\\anaconda\\lib\\site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: numpy<2,>=1.26.4 in e:\\anaconda\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in e:\\anaconda\\lib\\site-packages (from langchain) (1.4.22)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in e:\\anaconda\\lib\\site-packages (from langchain) (0.3.6)\n",
      "Requirement already satisfied: requests<3,>=2 in e:\\anaconda\\lib\\site-packages (from langchain) (2.26.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.35 in e:\\anaconda\\lib\\site-packages (from langchain) (0.3.35)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in e:\\anaconda\\lib\\site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in e:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in e:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in e:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in e:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (21.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in e:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in e:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.6)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in e:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in e:\\anaconda\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (4.12.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in e:\\anaconda\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (24.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in e:\\anaconda\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (1.33)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in e:\\anaconda\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.35->langchain) (3.0.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in e:\\anaconda\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in e:\\anaconda\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in e:\\anaconda\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in e:\\anaconda\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: idna in e:\\anaconda\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.2)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\anaconda\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: certifi in e:\\anaconda\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (2021.10.8)\n",
      "Requirement already satisfied: anyio in e:\\anaconda\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (2.2.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in e:\\anaconda\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\anaconda\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in e:\\anaconda\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in e:\\anaconda\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in e:\\anaconda\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in e:\\anaconda\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (1.1.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in e:\\anaconda\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd278a5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\POOJAK~1\\AppData\\Local\\Temp/ipykernel_19240/1719125727.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"LANGSMITH_TRACING\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"true\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"LANGSMITH_API_KEY\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetpass\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mgetpass\u001b[1;34m(self, prompt, stream)\u001b[0m\n\u001b[0;32m    986\u001b[0m                 \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m             )\n\u001b[1;32m--> 988\u001b[1;33m         return self._input_request(\n\u001b[0m\u001b[0;32m    989\u001b[0m             \u001b[0mprompt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    990\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"shell\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1049\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1051\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Interrupted by user\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid Message:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fad727",
   "metadata": {},
   "source": [
    "# 1) Installation - This installs LangChain library with OpenAI integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a214dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -qU \"langchain[openai]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808e267a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d05a20a",
   "metadata": {},
   "source": [
    "# 2) The following command is used to API key setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbc3bfe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter API key for OpenAI: ········\n"
     ]
    }
   ],
   "source": [
    "# This initializes a chat model using LangChain, specifying \"gpt-4o-mini\" as the model and \"openai\" as the provider\n",
    "\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a581a6ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2357cfd8",
   "metadata": {},
   "source": [
    "# 3) Model initialization - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4abf205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This initializes a chat model using LangChain, specifying \"gpt-4o-mini\" as the model and \"openai\" as the provider.\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b8d273",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da2d74fe",
   "metadata": {},
   "source": [
    "# 4) Message preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4646e654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='मुझे अपने देश से प्यार है।', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 22, 'total_tokens': 31, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_00428b782a', 'finish_reason': 'stop', 'logprobs': None}, id='run-8fbfc088-abde-45ff-ae6f-284984244a4c-0', usage_metadata={'input_tokens': 22, 'output_tokens': 9, 'total_tokens': 31, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This creates a list of messages, including a system message for instructions and a human message for the text to be translated\n",
    "\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"Translate the following from English into Hindi\"),\n",
    "    HumanMessage(\"I love my country\"),\n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215d2253",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53ea4549",
   "metadata": {},
   "source": [
    "# 4) Prompt Templates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da431f5",
   "metadata": {},
   "source": [
    "Prompt templates help to translate user input and parameters into instructions for a language model. This can be used to guide a model's response, helping it understand the context and generate relevant and coherent language-based output.\n",
    "\n",
    "Prompt Templates take as input a dictionary, where each key represents a variable in the prompt template to fill in.\n",
    "\n",
    "Prompt Templates output a PromptValue. This PromptValue can be passed to an LLM or a ChatModel, and can also be cast to a string or a list of messages. The reason this PromptValue exists is to make it easy to switch between strings and messages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872564c9",
   "metadata": {},
   "source": [
    "1) Importing and Creating the Prompt Template:\n",
    "This creates a ChatPromptTemplate with two messages: a system message for instructions and a user message \n",
    "for the text to be translated. The template has two variables: {language} and {text}.\n",
    "\n",
    "\n",
    "You're making a template for a conversation with the AI. This template has two parts:\n",
    "\n",
    "Instructions for the AI (called the \"system\" part)\n",
    "\n",
    "The text you want to translate (called the \"user\" part)\n",
    "\n",
    "The template leaves blank spaces for the language and the text, so you can fill them in later.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2acd2657",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_template = \"Translate the following from English into {language}\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ca5fb7",
   "metadata": {},
   "source": [
    "2) Invoking/Filling the Prompt Template:\n",
    "\n",
    "\n",
    "This step fills in the template variables. It sets the language to \"Hindi\" and the text to \"hi!\". \n",
    "The invoke method returns a ChatPromptValue object.\n",
    "\n",
    "You're taking the template you made and filling in the blank spaces. You're telling it to translate into Hindi, and the text to translate is \"hi!\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "627d7103",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_template.invoke({\"language\": \"Hindi\", \"text\": \"I love my country\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dfccf0",
   "metadata": {},
   "source": [
    "3) Displaying the Prompt:\n",
    "\n",
    "This displays the ChatPromptValue object, which contains the formatted prompt.\n",
    "\n",
    "\n",
    "When you just type prompt, you're asking to see what the filled-in template looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9442090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Translate the following from English into Marwari', additional_kwargs={}, response_metadata={}), HumanMessage(content='I love my country', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7bba98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab059b51",
   "metadata": {},
   "source": [
    "4) Converting to Messages:\n",
    "This converts the ChatPromptValue object into a list of message objects that can be used with the language model.\n",
    "\n",
    "prompt.to_messages() takes your filled-in template and turns it into a format that the AI can understand better.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de6e019c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Translate the following from English into Marwari', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I love my country', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.to_messages()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64d7dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de6e6585",
   "metadata": {},
   "source": [
    "5) Invoking the Model:\n",
    "\n",
    "This sends the formatted prompt to the language model for processing. The model translates the text as instructed.\n",
    "\n",
    "\n",
    "model.invoke(prompt) is like pressing \"Send\" on your message to the AI. You're asking it to read your filled-in template and do what it says (translate to Hindi)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "41fb6e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2394a9",
   "metadata": {},
   "source": [
    "6) Printing the Response:\n",
    "\n",
    "This prints the content of the model's response, which should be the Hindi translation of \"hi!\".\n",
    "\n",
    "print(response.content) shows you what the AI said back - in this case, it should be \"hi!\" translated into Hindi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b753bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "म्हारे देश स्यूँ प्यार है।\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce415086",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
